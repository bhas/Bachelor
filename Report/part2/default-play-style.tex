\section{Learning a default strategy}
\label{sec:part2}
In the previous chapter we created a calculator which can calculate the probability of winning with any hole cards in any game state. We will use the calculator in this section to estimate the strength of our hole cards.\\

Before we can learn our poker bot to adapt to opponents strategy we first need it to learn a default one. When the poker bot first joins a poker game it has no information about the opponent and in this case it must use a default strategy while it gathers more information.

In this chapter we will find a solution to the problem statement:

\vspace{4mm}
\begin{statementBox2}{Problem statement 2}
How can we develop a default strategy without having information about the opponents?
\end{statementBox2}
\vspace{4mm}

Even though players have different strategies they often have some decisions in common. Most players tend to play more aggressively the better their chances are of winning and likewise most players will fold if they have a weak hand. These tendencies can be used in a default strategy. The more popular decisions are more likely to be good. For instance most players agree that it is unwise to fold a pair of aces in pre-flop. 

The default strategy has to work against every strategy so it is impossible for it to be better than all of them. The goal is not for the default strategy to win, although that would be preferable, but instead to reduce the loses while it gathers information about the opponent.

\subsection{Design}
To develop a default strategy we have two options.

The first option is to directly program how the computer shall act in all situations. In this case the programmers need a deep insight in how to play poker in order to decide which decisions are optimal in the different situations. One can also use the expertise of professional poker players in case one lack the insight.

The second option is to develop a self-learning algorithm for the computer. Such an algorithm uses the concept \textit{watch and learn} by observing other players playing poker and trying to learn the strategy behind the decisions. This method requires that the computer has something to observe.

Since we do not have any particular insight in how to play poker and do not have expertise from any pro poker players, we will implement a self-learning algorithm. Another advantage by using this method is that the computer is not limited by our understanding of the game.

The University of Alberta has a research group that specializes in the field of artificial intelligence in poker. They have released a dataset containing data from ~18.000 real-life rounds of Texas hold'em limit poker. The dataset only contains the hole cards of the players who make it to the showdown, so there is no data about the hole cards of the players who fold. This data will be used to develop the default strategy.\\

To implement the self-learning algorithm we use an artificial neural networks (ANN), see section \ref{sec:nn}. The algorithm needs to recognise patterns in the players decisions and ANNs are very good at this.

We use an iterative development method to design the ANN for the algorithm. We start by designing a simple ANN and then move on to more complex ANNs.

\subsubsection{Artificial neural network (ANN)}
\label{sec:nn}
An artificial neural network (ANN) is inspired by the human brain. It is well suited for finding an approximation to a non-linear function. An ANN can take any number of inputs and return any number of outputs. 

An ANN is made up of neurons that are connected into a network. Each neuron takes a set of inputs and give one output. The output of a neuron is sent to the connected neurons. Each input has a weight that determines influence of the input. The neuron uses an input function to calculate the net input, usually the sum of all weighted inputs, and pass it on to the transfer function. The type of transfer function determines the output. A step function returns zero or one if the net input is above a certain threshold. This is useful for logical functions. If one needs a value between zero and one a sigmoid function can be used instead.

\begin{figure}[H]
  \center
    \includegraphics[scale=0.4]{images/nn/neuron.png}
  \caption{Model of a neuron. \label{fig:neuron}}
\end{figure}

The neurons in an ANN are distributed in layers as shown in figure \ref{fig:mlp}. The coloured circles represents neurons and the arrows represents the connections between the neurons. There are three types of layers, an input layer, a hidden layer, and an output layer. An ANNs consists of one input layer and one output layer but may contain any number of hidden layers. The simplest type of ANN is the perceptron which has no hidden layers. It is used for single calculations. A multilayer perceptron is another type of ANN which contains hidden layers. It is used for more complex domains with multiple layers of computations. 

\input{other/models/perceptron.tex}
\vspace{4mm}
\input{other/models/multi-perceptron.tex}

The ANN can be trained using a training set of inputs. Using supervised learning, in contrast to unsupervised learning, one must also supply an expected output. For each input it will adjust the weights in order to get closer to the expected output. It will continue doing this until the outputs are close enough to the expected outputs. Different algorithms exist for this. 

Backpropagation is the most common algorithm for supervised ANNs. It adjust the weights from the end (the output neurons) back to the start (the input neurons).

After the training the ANN can be validated to see if it works. This is done using a test set different from the training set and see if the results of the ANN matches the expected results of the test set.

\subsubsection{First ANN design}
For the first attempt we design a simple perceptron. The perceptron takes two inputs, and gives two outputs. 

The first input is the hand strength. We use the calculator from section \ref{sec:part1} to calculate the probability of winning against a single opponent. The reason we always find the probability against a single opponent is because the probability of winning decreases drastically as the number of opponents increases. We use the absolute hand strength rather than a hand strength relative to the number of players. 
This makes it easier to compare the hands strengths in situations with different numbers of players. The number of players is instead the second input.

The first output is whether or not to be defensive by checking or calling. The second output is whether or not to be aggressive by betting or calling. The outputs will both be zero in case it is best to fold. 
The perceptron uses a step function as a transfer function in both output neurons.
\input{other/models/default-nn1.tex}

The perceptron is more likely to be aggressive the higher the number of opponents is and the stronger the hand is. The problem is that the perceptron almost never acts aggressively. From our test set we expect the perceptron to be more aggressive. 

\subsubsection{Second ANN design}
Since the first attempt designing a perceptron did not work properly we try to design a multilayer perceptron (MLP) with more inputs.

The MLP is taking the same inputs as the earlier discussed perceptron, but it now takes three additional inputs: The chips of the player, the cost for the player to call, and the pot.

The MLP has one hidden layer with two hidden neurons. One hidden neuron to calculate the likelihood of winning and another for the economically aspect.

\input{other/models/default-nn2.tex}

Vi har ikke nået mere så du behøver ikke læse videre :)

\subsection{Test}
To test our first simple neural network a.k.a the perceptron, we ran through x games in the dataset. The neural network is not able to get particular smarter when running through an additional set of entries as the data is from different players and x games should be sufficient for the neural network to gain some kind of knowledge on how to play as the goal of this strategy is not to have a bot that can beat the opponents but minimize the loses.
The neural network now had to learn from the dataset 

\subsection{Discussion}
When artificial intelligence starts out by playing the games of poker it doesn't have any kind of information about the opponents. So to make sure that the bot wont just go keep throwing away the bank roll. Instead we wanted the bot to minimizes our losses so that we would still have a decent bank roll when we have gathered information about the opponents so that the bot could make qualified guesses at what move would be the most appropriate in terms of the current opponent. The default player was never meant to be on the same level as a human player, but humans are only in a slightly better position than the default bot. The human player can like the bot only see the hole and community cards, but a human is also able to make a profile of the bot in their head. This means that they can learn how the bot decides and exploit this. 
This is one of the reasons that we chose to go with a neural network. In a neural network we are able to of course train the network to make correct decisions based on the targeted output that we give it.
But as the game proceeds the neural network has an input which will weight when we have enough information about the opponents to shift our gameplay from the default play style to a more adaptive one.
The time that it takes a human player to learn about the bot and adapt to it, should be the same for the bot. So if we imagine a human player who is good enough to decipher the way the bot is playing and adapt to it. When the human player does that, the bot should also have started to change its ways. Slowly as the bot learn it will adapt more and more to the opponent so when we have enough information the bot will shift completely and disregard the default play style.
\subsection{Conclusion}